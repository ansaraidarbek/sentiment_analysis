{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanza examples\n",
    "\n",
    "Additional information: https://stanfordnlp.github.io/stanza/usage.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stanza will try to download resuorces needed to build the specified pipeline. \n",
    "\n",
    "You can download the models beforehand, see details here: https://stanfordnlp.github.io/stanza/faq.html#troubleshooting-download--installation\n",
    "\n",
    "Below is a definition of a pipeline for tokenization, lemmatization, and POS-tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 19:25:20 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "========================\n",
      "\n",
      "2023-09-12 19:25:20 INFO: Using device: cpu\n",
      "2023-09-12 19:25:20 INFO: Loading: tokenize\n",
      "2023-09-12 19:25:20 INFO: Loading: pos\n",
      "2023-09-12 19:25:20 INFO: Loading: lemma\n",
      "2023-09-12 19:25:20 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,lemma', download_method=\"reuse_resources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text processning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('It is a truth universally acknowledged, that a single man in possession of a good fortune must be in want of a wife. However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered as the rightful property of some one or other of their daughters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It it PRON\n",
      "is be AUX\n",
      "a a DET\n",
      "truth truth NOUN\n",
      "universally universally ADV\n",
      "acknowledged acknowledge VERB\n",
      ", , PUNCT\n",
      "that that SCONJ\n",
      "a a DET\n",
      "single single ADJ\n",
      "man man NOUN\n",
      "in in ADP\n",
      "possession possession NOUN\n",
      "of of ADP\n",
      "a a DET\n",
      "good good ADJ\n",
      "fortune fortune NOUN\n",
      "must must AUX\n",
      "be be AUX\n",
      "in in ADP\n",
      "want want NOUN\n",
      "of of ADP\n",
      "a a DET\n",
      "wife wife NOUN\n",
      ". . PUNCT\n",
      "However however ADV\n",
      "little little ADJ\n",
      "known know VERB\n",
      "the the DET\n",
      "feelings feeling NOUN\n",
      "or or CCONJ\n",
      "views view NOUN\n",
      "of of ADP\n",
      "such such DET\n",
      "a a DET\n",
      "man man NOUN\n",
      "may may AUX\n",
      "be be AUX\n",
      "on on ADP\n",
      "his he PRON\n",
      "first first ADJ\n",
      "entering enter VERB\n",
      "a a DET\n",
      "neighbourhood neighbourhood NOUN\n",
      ", , PUNCT\n",
      "this this DET\n",
      "truth truth NOUN\n",
      "is be AUX\n",
      "so so ADV\n",
      "well well ADV\n",
      "fixed fix VERB\n",
      "in in ADP\n",
      "the the DET\n",
      "minds mind NOUN\n",
      "of of ADP\n",
      "the the DET\n",
      "surrounding surround VERB\n",
      "families family NOUN\n",
      ", , PUNCT\n",
      "that that SCONJ\n",
      "he he PRON\n",
      "is be AUX\n",
      "considered consider VERB\n",
      "as as ADP\n",
      "the the DET\n",
      "rightful rightful ADJ\n",
      "property property NOUN\n",
      "of of ADP\n",
      "some some DET\n",
      "one one NUM\n",
      "or or CCONJ\n",
      "other other ADJ\n",
      "of of ADP\n",
      "their they PRON\n",
      "daughters daughter NOUN\n",
      ". . PUNCT\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sentences:\n",
    "    for word in sentence.words:\n",
    "        print(word.text, word.lemma, word.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 19:25:29 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "2023-09-12 19:25:29 INFO: Using device: cpu\n",
      "2023-09-12 19:25:29 INFO: Loading: tokenize\n",
      "2023-09-12 19:25:29 INFO: Loading: sentiment\n",
      "2023-09-12 19:25:30 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment', download_method=\"reuse_resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('It is a truth universally acknowledged, that a single man in possession of a good fortune must be in want of a wife. However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered as the rightful property of some one or other of their daughters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models assign a sentiment score to each sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> 1\n",
      "1 -> 2\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(doc.sentences):\n",
    "    print(\"%d -> %d\" % (i, sentence.sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Yelp review contains two sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('I could care less... The interior is just beautiful.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> 0\n",
      "1 -> 2\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(doc.sentences):\n",
    "    print(\"%d -> %d\" % (i, sentence.sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can switch off sentence splitting. Don't feed reviews by one to the model; instead use double line (\\n\\n) to separate individual reviews in a long documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 19:25:37 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "2023-09-12 19:25:37 INFO: Using device: cpu\n",
      "2023-09-12 19:25:37 INFO: Loading: tokenize\n",
      "2023-09-12 19:25:37 INFO: Loading: sentiment\n",
      "2023-09-12 19:25:37 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment', download_method=None, tokenize_no_ssplit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('I could care less... The interior is just beautiful.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> 2\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(doc.sentences):\n",
    "    print(\"%d -> %d\" % (i, sentence.sentiment))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
